{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/tutorial/random-forests-classifier-python\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Y = original['Danceability']\n",
    "original.drop(['Danceability'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOptions(data, option = 'max'):\n",
    "    if data.isna().sum() != len(data):\n",
    "        if option == 'max':\n",
    "            return data.value_counts().idxmax()\n",
    "        elif option == 'mean':\n",
    "            return data.mean()\n",
    "        elif option == 'median':\n",
    "            return data.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyID(original, newData):\n",
    "    noInNewData = original[~original['id'].isin(newData['id'])]\n",
    "    return pd.concat([newData, noInNewData], ignore_index=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtistComposerDance(data, nameColumnFill):\n",
    "\n",
    "    listArtist = data['Artist'].unique()\n",
    "    listComposer = data['Composer'].unique()\n",
    "    \n",
    "    filter = list(product(listArtist, listComposer))\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        artist, composer = i[0], i[1]\n",
    "        filterData = data[(data['Artist'] == artist) & (data['Composer'] == composer) ]\n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtist(data, nameColumnFill):\n",
    "    listDance = data['Artist'].unique()\n",
    "    filter = listDance\n",
    "\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        dance = i\n",
    "        filterData = data[ (data['Artist'] == dance)]\n",
    "    \n",
    "    \n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFillData(data, nameColumnFill):\n",
    "    if not data.isnull().any().any():\n",
    "        return data\n",
    "    else:\n",
    "        for nameColumn in nameColumnFill:\n",
    "            fillInfo = fillOptions(data[nameColumn], option = 'max')\n",
    "            if fillInfo != None:\n",
    "                data.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessing(original):\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    data = original.copy()\n",
    "\n",
    "    nameColumnFill = ['Energy', 'Key', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms', 'Duration_ms', 'Views', 'Likes', \"Stream\" , \"Comments\"]\n",
    "\n",
    "    # License and official_video\n",
    "    data['Licensed'].fillna(data['official_video'], inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(data['Licensed'], inplace=True)\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['Licensed'].replace({True: 1, False: 0})\n",
    "    data['official_video'].replace({True: 1, False: 0})\n",
    "\n",
    "    # Create new class = 'Unknown'\n",
    "    data['Composer'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Artist'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Album_type'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    newData = filterArtistComposerDance(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterArtist(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterFillData(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    #Transform type key to use as class\n",
    "    data['Key'] = data['Key'].astype(int)\n",
    "    data['Key'] = data['Key'].astype(str)\n",
    "\n",
    "    data = data.sort_values('id')\n",
    "\n",
    "    # DELETE Track, Album, Uri, Url_spotify, Url_youtube, Description, Title, Channel, id, Comments\n",
    "    data.drop(['Track', 'Album', 'Uri', 'Url_spotify', 'Url_youtube', 'Description', 'Title', 'Channel', 'id'], axis=1, inplace=True)\n",
    "\n",
    "    pd.options.mode.chained_assignment = 'warn'\n",
    "\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertEncoderPD(data, prefix = 'key'):\n",
    "    titleKeys = []\n",
    "    for i in range(data.shape[1]):\n",
    "        titleKeys.append(f'{prefix}_{i}')\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns= titleKeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTraining(data):\n",
    "\n",
    "    encoderKey = OneHotEncoder()\n",
    "    encodedKey = encoderKey.fit_transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = OneHotEncoder()\n",
    "    encodedKeyAlbumType = encoderAlbumType.fit_transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = OneHotEncoder()\n",
    "    encodedKeyComposer = encoderComposer.fit_transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = LabelEncoder()\n",
    "    encodedArtist = encoderArtist.fit_transform(data[['Artist']])\n",
    "    encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaledData = scaler.fit_transform(data)\n",
    "\n",
    "    scaledData_pd = pd.DataFrame(data=scaledData, columns= data.columns)\n",
    "\n",
    "    return {\"key\": encoderKey, 'AlbumType': encoderAlbumType, 'Composer': encoderComposer, \"Artist\":encoderArtist} , scaler, data, scaledData_pd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTesting(encoder, scalerStandard, data):\n",
    "\n",
    "    encoderKey = encoder['key']\n",
    "    encodedKey = encoderKey.transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = encoder['AlbumType']\n",
    "    encodedKeyAlbumType = encoderAlbumType.transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = encoder['Composer']\n",
    "    encodedKeyComposer = encoderComposer.transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = encoder['Artist']\n",
    "    encodedArtist = encoderArtist.transform(data[['Artist']])\n",
    "    encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "    scaler = scalerStandard\n",
    "    scaledData = scaler.transform(data)\n",
    "\n",
    "    scaledData_pd = pd.DataFrame(data=scaledData, columns= data.columns)\n",
    "\n",
    "    return data, scaledData_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataPreprocessing(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\fintech\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoders, scalerStandard, data, scaledData_pd = createEncodeDataTraining(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\fintech\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "dataTest = dataPreprocessing(test)\n",
    "testOriginal, testScaled = createEncodeDataTesting(encoders, scalerStandard, dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Licensed</th>\n",
       "      <th>official_video</th>\n",
       "      <th>Comments</th>\n",
       "      <th>key_0</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>AlbumType_0</th>\n",
       "      <th>AlbumType_1</th>\n",
       "      <th>AlbumType_2</th>\n",
       "      <th>AlbumType_3</th>\n",
       "      <th>Composer_0</th>\n",
       "      <th>Composer_1</th>\n",
       "      <th>Composer_2</th>\n",
       "      <th>Composer_3</th>\n",
       "      <th>Composer_4</th>\n",
       "      <th>Composer_5</th>\n",
       "      <th>Composer_6</th>\n",
       "      <th>Composer_7</th>\n",
       "      <th>Composer_8</th>\n",
       "      <th>Composer_9</th>\n",
       "      <th>Composer_10</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.398009</td>\n",
       "      <td>-3.751298</td>\n",
       "      <td>-0.478774</td>\n",
       "      <td>2.622749</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>-0.277188</td>\n",
       "      <td>-0.770495</td>\n",
       "      <td>-1.255897</td>\n",
       "      <td>-0.929988</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>-0.281016</td>\n",
       "      <td>-0.449627</td>\n",
       "      <td>-1.525410</td>\n",
       "      <td>-1.783728</td>\n",
       "      <td>-0.110374</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>-0.472989</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>5.774080</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>2.390037</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>0.091884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.634465</td>\n",
       "      <td>-1.286495</td>\n",
       "      <td>-0.580595</td>\n",
       "      <td>2.397207</td>\n",
       "      <td>4.845583</td>\n",
       "      <td>0.030312</td>\n",
       "      <td>0.893809</td>\n",
       "      <td>0.944228</td>\n",
       "      <td>-0.447282</td>\n",
       "      <td>-0.352389</td>\n",
       "      <td>-0.363223</td>\n",
       "      <td>-0.485495</td>\n",
       "      <td>-1.525410</td>\n",
       "      <td>-1.783728</td>\n",
       "      <td>-0.125275</td>\n",
       "      <td>2.823250</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>-0.472989</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>2.856960</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>-0.726161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195801</td>\n",
       "      <td>-1.682721</td>\n",
       "      <td>-0.479762</td>\n",
       "      <td>2.377255</td>\n",
       "      <td>4.604147</td>\n",
       "      <td>-0.268505</td>\n",
       "      <td>-0.606524</td>\n",
       "      <td>-1.205320</td>\n",
       "      <td>-0.645164</td>\n",
       "      <td>-0.352389</td>\n",
       "      <td>-0.363223</td>\n",
       "      <td>-0.452510</td>\n",
       "      <td>-1.525410</td>\n",
       "      <td>-1.783728</td>\n",
       "      <td>-0.125275</td>\n",
       "      <td>2.823250</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>-0.472989</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>-1.236263</td>\n",
       "      <td>5.780036</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>2.390037</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>0.942651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.529179</td>\n",
       "      <td>0.335114</td>\n",
       "      <td>-0.642875</td>\n",
       "      <td>-0.505931</td>\n",
       "      <td>-0.263873</td>\n",
       "      <td>-0.275451</td>\n",
       "      <td>-0.069520</td>\n",
       "      <td>0.995715</td>\n",
       "      <td>0.348878</td>\n",
       "      <td>0.494190</td>\n",
       "      <td>0.252463</td>\n",
       "      <td>1.207829</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>2.114213</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>2.169381</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>0.746320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073990</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.659680</td>\n",
       "      <td>-0.522406</td>\n",
       "      <td>-0.261251</td>\n",
       "      <td>-0.258129</td>\n",
       "      <td>-0.954963</td>\n",
       "      <td>-0.763974</td>\n",
       "      <td>0.339028</td>\n",
       "      <td>0.972284</td>\n",
       "      <td>0.439960</td>\n",
       "      <td>-0.470537</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>0.031552</td>\n",
       "      <td>2.823250</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>-0.472989</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>2.390037</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>1.138982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17165</th>\n",
       "      <td>1.896767</td>\n",
       "      <td>0.315032</td>\n",
       "      <td>-0.592458</td>\n",
       "      <td>-0.131894</td>\n",
       "      <td>-0.263873</td>\n",
       "      <td>-0.279136</td>\n",
       "      <td>0.533073</td>\n",
       "      <td>-1.033371</td>\n",
       "      <td>-1.132043</td>\n",
       "      <td>-0.121606</td>\n",
       "      <td>-0.365754</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>-0.125891</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>2.915808</td>\n",
       "      <td>-0.472989</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>3.727142</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>-0.726161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17166</th>\n",
       "      <td>2.004703</td>\n",
       "      <td>1.299226</td>\n",
       "      <td>0.674876</td>\n",
       "      <td>-0.522324</td>\n",
       "      <td>-0.263873</td>\n",
       "      <td>-0.277374</td>\n",
       "      <td>0.528974</td>\n",
       "      <td>1.826279</td>\n",
       "      <td>-0.643512</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>-0.365192</td>\n",
       "      <td>-0.489278</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>-0.125891</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>2.114213</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>14.524989</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>-0.431665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17167</th>\n",
       "      <td>0.974288</td>\n",
       "      <td>0.674550</td>\n",
       "      <td>-0.277107</td>\n",
       "      <td>-0.272629</td>\n",
       "      <td>-0.263873</td>\n",
       "      <td>-0.251575</td>\n",
       "      <td>-0.446653</td>\n",
       "      <td>1.607898</td>\n",
       "      <td>-0.765362</td>\n",
       "      <td>-0.353013</td>\n",
       "      <td>-0.366241</td>\n",
       "      <td>0.191422</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>-0.125891</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>-0.472989</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>3.561078</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>2.388939</td>\n",
       "      <td>-1.236263</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>3.164407</td>\n",
       "      <td>1.138982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17168</th>\n",
       "      <td>0.473816</td>\n",
       "      <td>-0.861336</td>\n",
       "      <td>3.225361</td>\n",
       "      <td>-0.326461</td>\n",
       "      <td>-0.263873</td>\n",
       "      <td>-0.273113</td>\n",
       "      <td>0.045260</td>\n",
       "      <td>1.169517</td>\n",
       "      <td>-1.012757</td>\n",
       "      <td>-0.353135</td>\n",
       "      <td>-0.327221</td>\n",
       "      <td>-0.506846</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>-0.125891</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>-0.472989</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>3.762241</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>-0.374004</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>3.727142</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>0.549990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17169</th>\n",
       "      <td>2.026569</td>\n",
       "      <td>0.703916</td>\n",
       "      <td>0.141053</td>\n",
       "      <td>-0.522419</td>\n",
       "      <td>4.851198</td>\n",
       "      <td>-0.261808</td>\n",
       "      <td>-1.841635</td>\n",
       "      <td>1.327516</td>\n",
       "      <td>-0.377093</td>\n",
       "      <td>-0.352498</td>\n",
       "      <td>-0.364903</td>\n",
       "      <td>-0.511990</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>-0.125891</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>2.114213</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.173188</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.280814</td>\n",
       "      <td>-0.264415</td>\n",
       "      <td>-0.363302</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>-0.418596</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>-0.173009</td>\n",
       "      <td>-0.526991</td>\n",
       "      <td>-0.460961</td>\n",
       "      <td>-0.068847</td>\n",
       "      <td>-0.350022</td>\n",
       "      <td>2.673766</td>\n",
       "      <td>-0.277785</td>\n",
       "      <td>-0.268302</td>\n",
       "      <td>-0.239167</td>\n",
       "      <td>-0.088689</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.418404</td>\n",
       "      <td>-0.316015</td>\n",
       "      <td>-1.740538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17170 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Energy  Loudness  Speechiness  Acousticness  Instrumentalness  \\\n",
       "0     -1.398009 -3.751298    -0.478774      2.622749         -0.263525   \n",
       "1     -0.634465 -1.286495    -0.580595      2.397207          4.845583   \n",
       "2      0.195801 -1.682721    -0.479762      2.377255          4.604147   \n",
       "3     -0.529179  0.335114    -0.642875     -0.505931         -0.263873   \n",
       "4      0.073990  0.619057    -0.659680     -0.522406         -0.261251   \n",
       "...         ...       ...          ...           ...               ...   \n",
       "17165  1.896767  0.315032    -0.592458     -0.131894         -0.263873   \n",
       "17166  2.004703  1.299226     0.674876     -0.522324         -0.263873   \n",
       "17167  0.974288  0.674550    -0.277107     -0.272629         -0.263873   \n",
       "17168  0.473816 -0.861336     3.225361     -0.326461         -0.263873   \n",
       "17169  2.026569  0.703916     0.141053     -0.522419          4.851198   \n",
       "\n",
       "       Liveness   Valence     Tempo  Duration_ms     Views     Likes  \\\n",
       "0     -0.277188 -0.770495 -1.255897    -0.929988 -0.152250 -0.281016   \n",
       "1      0.030312  0.893809  0.944228    -0.447282 -0.352389 -0.363223   \n",
       "2     -0.268505 -0.606524 -1.205320    -0.645164 -0.352389 -0.363223   \n",
       "3     -0.275451 -0.069520  0.995715     0.348878  0.494190  0.252463   \n",
       "4     -0.258129 -0.954963 -0.763974     0.339028  0.972284  0.439960   \n",
       "...         ...       ...       ...          ...       ...       ...   \n",
       "17165 -0.279136  0.533073 -1.033371    -1.132043 -0.121606 -0.365754   \n",
       "17166 -0.277374  0.528974  1.826279    -0.643512 -0.352473 -0.365192   \n",
       "17167 -0.251575 -0.446653  1.607898    -0.765362 -0.353013 -0.366241   \n",
       "17168 -0.273113  0.045260  1.169517    -1.012757 -0.353135 -0.327221   \n",
       "17169 -0.261808 -1.841635  1.327516    -0.377093 -0.352498 -0.364903   \n",
       "\n",
       "         Stream  Licensed  official_video  Comments     key_0     key_1  \\\n",
       "0     -0.449627 -1.525410       -1.783728 -0.110374 -0.354202 -0.342958   \n",
       "1     -0.485495 -1.525410       -1.783728 -0.125275  2.823250 -0.342958   \n",
       "2     -0.452510 -1.525410       -1.783728 -0.125275  2.823250 -0.342958   \n",
       "3      1.207829  0.655562        0.560624 -0.002817 -0.354202 -0.342958   \n",
       "4     -0.470537  0.655562        0.560624  0.031552  2.823250 -0.342958   \n",
       "...         ...       ...             ...       ...       ...       ...   \n",
       "17165  0.011762  0.655562        0.560624 -0.125891 -0.354202  2.915808   \n",
       "17166 -0.489278  0.655562        0.560624 -0.125891 -0.354202 -0.342958   \n",
       "17167  0.191422  0.655562        0.560624 -0.125891 -0.354202 -0.342958   \n",
       "17168 -0.506846  0.655562        0.560624 -0.125891 -0.354202 -0.342958   \n",
       "17169 -0.511990  0.655562        0.560624 -0.125891 -0.354202 -0.342958   \n",
       "\n",
       "          key_2     key_3     key_4     key_5     key_6     key_7     key_8  \\\n",
       "0     -0.472989 -0.327151  5.774080 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "1     -0.472989 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "2     -0.472989 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "3      2.114213 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "4     -0.472989 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "17165 -0.472989 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "17166  2.114213 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "17167 -0.472989 -0.327151 -0.173188 -0.262265  3.561078 -0.264415 -0.363302   \n",
       "17168 -0.472989 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "17169  2.114213 -0.327151 -0.173188 -0.262265 -0.280814 -0.264415 -0.363302   \n",
       "\n",
       "          key_9    key_10  AlbumType_0  AlbumType_1  AlbumType_2  AlbumType_3  \\\n",
       "0     -0.265799 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "1     -0.265799 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "2     -0.265799 -0.313108    -0.418596    -1.236263     5.780036    -0.526991   \n",
       "3     -0.265799 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "4     -0.265799 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "...         ...       ...          ...          ...          ...          ...   \n",
       "17165 -0.265799 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "17166 -0.265799 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "17167 -0.265799 -0.313108     2.388939    -1.236263    -0.173009    -0.526991   \n",
       "17168  3.762241 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "17169 -0.265799 -0.313108    -0.418596     0.808889    -0.173009    -0.526991   \n",
       "\n",
       "       Composer_0  Composer_1  Composer_2  Composer_3  Composer_4  Composer_5  \\\n",
       "0       -0.460961   -0.068847   -0.350022   -0.374004   -0.277785   -0.268302   \n",
       "1       -0.460961   -0.068847    2.856960   -0.374004   -0.277785   -0.268302   \n",
       "2       -0.460961   -0.068847   -0.350022   -0.374004   -0.277785   -0.268302   \n",
       "3        2.169381   -0.068847   -0.350022   -0.374004   -0.277785   -0.268302   \n",
       "4       -0.460961   -0.068847   -0.350022   -0.374004   -0.277785   -0.268302   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "17165   -0.460961   -0.068847   -0.350022   -0.374004   -0.277785    3.727142   \n",
       "17166   -0.460961   14.524989   -0.350022   -0.374004   -0.277785   -0.268302   \n",
       "17167   -0.460961   -0.068847   -0.350022   -0.374004   -0.277785   -0.268302   \n",
       "17168   -0.460961   -0.068847   -0.350022   -0.374004   -0.277785    3.727142   \n",
       "17169   -0.460961   -0.068847   -0.350022    2.673766   -0.277785   -0.268302   \n",
       "\n",
       "       Composer_6  Composer_7  Composer_8  Composer_9  Composer_10    Artist  \n",
       "0       -0.239167   -0.088689   -0.416287    2.390037    -0.316015  0.091884  \n",
       "1       -0.239167   -0.088689   -0.416287   -0.418404    -0.316015 -0.726161  \n",
       "2       -0.239167   -0.088689   -0.416287    2.390037    -0.316015  0.942651  \n",
       "3       -0.239167   -0.088689   -0.416287   -0.418404    -0.316015  0.746320  \n",
       "4       -0.239167   -0.088689   -0.416287    2.390037    -0.316015  1.138982  \n",
       "...           ...         ...         ...         ...          ...       ...  \n",
       "17165   -0.239167   -0.088689   -0.416287   -0.418404    -0.316015 -0.726161  \n",
       "17166   -0.239167   -0.088689   -0.416287   -0.418404    -0.316015 -0.431665  \n",
       "17167   -0.239167   -0.088689   -0.416287   -0.418404     3.164407  1.138982  \n",
       "17168   -0.239167   -0.088689   -0.416287   -0.418404    -0.316015  0.549990  \n",
       "17169   -0.239167   -0.088689   -0.416287   -0.418404    -0.316015 -1.740538  \n",
       "\n",
       "[17170 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledData_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(scaledData_pd, training_Y, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "# rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# # Train the model on training data\n",
    "# rf.fit(train_features, train_labels)\n",
    "\n",
    "# filename = \"random_forest_regressor.joblib\"\n",
    "# pickle.dump(rf, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the forest's predict method on the test data\n",
    "# predictions = rf.predict(test_features)\n",
    "# # Calculate the absolute errors\n",
    "# predictions = np.rint(predictions)\n",
    "# errors = abs(predictions - test_labels)\n",
    "# # Print out the mean absolute error (mae)\n",
    "# print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "# predictionsTest = rf.predict(testScaled)\n",
    "# predictionsTest = np.rint(predictionsTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictionTest_pd = pd.DataFrame(data = predictionsTest, columns= ['Danceability'])\n",
    "# predictionTest_pd.to_csv('RandomForestRegressor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "# # you can use loaded model to compute predictions\n",
    "# predicted = loaded_model.predict(test_features)\n",
    "\n",
    "# predicted = np.rint(predicted)\n",
    "# errors = abs(predicted - test_labels)\n",
    "# # Print out the mean absolute error (mae)\n",
    "# print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "best_params = {'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha': 0.4, 'n_estimators': 400, 'min_child_weight': 4, 'max_depth': 30, 'learning_rate': 0.01, 'gamma': 0.3, 'colsample_bytree': 0.6, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.8, 'random_state': 0}\n",
    "default_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'booster': 'gbtree',\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'gamma': 0,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 1,\n",
    "    'random_state': 0,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "best_model = XGBRegressor(**default_params)\n",
    "best_model.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE without CV: 1.7788469836949932\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = best_model.predict(test_features)\n",
    "mae = mean_absolute_error(test_labels, preds)\n",
    "print(f\"MAE without CV: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictionsTest = best_model.predict(testScaled)\n",
    "predictionsTest = np.rint(predictionsTest)\n",
    "predictionTest_pd = pd.DataFrame(data = predictionsTest, columns= ['Danceability'])\n",
    "predictionTest_pd.to_csv('XGB.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.rint(predictionsTest)\n",
    "preds = preds.astype(int)\n",
    "preds = pd.DataFrame(preds, columns=['Danceability'])\n",
    "preds['id'] = preds.index + 17170\n",
    "preds = preds[['id', 'Danceability']]\n",
    "preds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
